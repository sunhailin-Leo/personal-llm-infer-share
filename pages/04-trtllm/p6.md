# 推理引擎之 TensorRT-LLM（六）
其他优化~

* INT8/INT4 量化：也是 TRT 的武器库出品
* FP8 量化（什么时候能用上 Hopper/Ada Lovelace 架构再说吧）
  * KV-Cache 量化：节省显存占用和通信带宽
  * 权重量化：小 Batch 比大 Batch 收益明显
