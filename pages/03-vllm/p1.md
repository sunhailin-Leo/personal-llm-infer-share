# 推理引擎之 vllm（一）

左侧是 vllm 的【简易】架构图

核心组件是 LLMEngine 类，外层接口类 LLM 和 AsyncLLMEngine 都是对 LLMEngine 的封装

LLMEngine 有两个核心组件：
* Scheduler：从等待队列中选择要处理的请求
* Worker：使用模型对被调度的请求进行推理
* BlockSpaceManager：块表的维护(用于 KV Cache 等)