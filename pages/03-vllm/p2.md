# 推理引擎之 vllm（二）
Worker 负责模型的执行

如果模型过大，可以将模型切分到多个 Worker 共同完成请求的处理（Ray 框架）

举个🌰：假设模型有 4 层，现在有 4 张卡，可以设置 Tensor Parallel=4，则将模型切分为 4 份，每张卡存放模型的一部分。

<div style="text-align: center"><img src="https://pic2.zhimg.com/v2-a996b992fc6a363f69b2af4c4b87fcb1_1440w.jpg" width="600px" style="display: inline;"/></div>

Worker 还有另外一个核心组件是 CacheEngine，它负责 KV cache 的初始化以及 KV cache 的相关操作