# 推理引擎之 vllm（六）
Scheduler 使用 iterative-level（Continuous batching） 进行调度，请求在生成一个 token 后会被重新调度。

<img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2024%2F1023%2Fb7aa75ccj00slsp3c00b8d200u0007ag00id004g.jpg&thumbnail=660x2147483647&quality=80&type=jpg" width="500" height="100">

😁好处：
* 在每一轮新迭代时选择不固定数量的请求进行处理（即 batch size 都不一定相同），因此能尽可能多处理请求
* 简化资源管理和调度

😭缺点：
* 调度开销大，在调度期间 CPU 要用来处理请求，GPU 空闲无法得到充分利用
* KV Cache 重读，需要在 Global Memory 与 Shared Memory 之间反复搬运（原因就是 Prefill 和 Decoding 的计算特性不同）
