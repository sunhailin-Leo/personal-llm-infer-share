# FlashAttention（二）
图解 FlashAttention 大致流程

<div style="text-align: center"><img src="../../assets/img-13.png" width="550px" style="display: inline;"/></div>

在标准注意力实现中，从 HBM 加载和写入键、查询和值的成本较高。它将键、查询和值从 HBM 加载到 GPU 片上 SRAM，执行注意力机制的单个步骤，将其写回 HBM，并为每个注意力步骤重复此操作。

⭐：而 FlashAttention 只需加载一次键、查询和值，融合注意力机制的操作，然后将其写回。