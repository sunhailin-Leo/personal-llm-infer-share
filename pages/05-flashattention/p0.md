# 从 PagedAttention 到 FlashAttention
经典 FlashAttention 论文图

<div style="text-align: center"><img src="https://pica.zhimg.com/v2-4d2e48bf362cec58f2effdd197be2af8_1440w.jpg" width="700px" style="display: inline;"/></div>

在了解完之前铺垫的硬件知识后，对于 FA 的一个优化点已经了解 1/3 了（上图最左侧部分）

最右侧同理，Fused Kernel 说白了就是 TensorRT 的 Graph Rewriting 操作，简化计算图

接下来重点就是围绕，上图中间部分进行展开~